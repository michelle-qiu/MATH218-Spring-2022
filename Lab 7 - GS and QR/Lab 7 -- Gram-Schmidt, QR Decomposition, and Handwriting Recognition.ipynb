{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gram-Schmidt, QR Decomposition, and Least Squares\n",
    "\n",
    "As we saw in class, the Gram-Schmidt (from here on: GS) process involves repeated projection of vectors onto other vectors resulting in transforming an arbitrary matrix into an *orthonormal* matrix. By keeping track of the process, we compute a *QR decomposition* of a matrix. Today we will code algorithms for Gram-Schmidt and QR Decomposition as learned in class. We will see how QR decomposition gives us a straightforward way of solving Least Squares problems and compare the algorithm to the LU algorithm from last week's lab.\n",
    "\n",
    "> ## Make a copy of this notebook (File menu -> Make a Copy...)\n",
    "\n",
    "## Projections\n",
    "\n",
    "The Gram-Schmidt algorithm proceeds by projecting vectors onto other vectors. In this first part, we will code a `project(u,v)` method that will return the orthogonal projection of a vector *v* onto the vector *u*.\n",
    "\n",
    "**Question 1** We define $\\mbox{proj}_u(v)$ to be the projection of $v$ onto $u$. \n",
    "1. Write down a formula for this projection using dot products, as learned in class. <br><br>\n",
    "1. What should the dot product of of $u$ and $v-\\mbox{proj}_u(v)$ be? Why? Check that this is indeed the case with your formula given above.\n",
    "\n",
    "**Question 2** Write a function `project(u,v)` that takes two vectors *u* and *v* and returns the orthogonal projection of *v* onto *u*. Recall that if *u* and *v* are vectors (1-D arrays), `u@v` returns their dot product. Test your code by computing a few projections by hand, then using your function. Does your code returns projections that satisfy the second condition from Question 1? \n",
    "\n",
    "You may have noticed that for many vectors that *should* be orthogonal, you don't get exactly zero, but rather a very small positive number. This is a very typical occurence for floating point numbers. We often need to check whether a particular quantity is zero. Due to this floating point issue, the code `a==0` is rarely sufficient. Instead, we define a *tolerance* $\\tau$: we say that $a=0$ for our purposes if $|a|<\\tau$. For this lab (and most others), we will take $\\tau=10^{-8}$.\n",
    "\n",
    "**Question 3** Recall that if $u=0$, then $\\mbox{proj}_u(v) = 0$. Add this to your code for *project(u,v)*. Since vectors are rarely *exactly* zero, define a vector to be zero if its norm is less than $10^{-8}$. You can use `np.norm(v)` to find a vector's norm, but recall that the dot product of a vector with itself is the square of the norm, so it may be faster to use that and avoid square roots...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gram-Schmidt\n",
    "\n",
    "Suppose that we have an $m\\times n$ matrix *A* whose columns are $u_1,\\ldots,u_n$. We aim to find an *orthonormal* basis for the column space of *A* by using the Gram-Schmidt process. However, the Gram-Schmidt process is more general: it takes any linearly independent list of vectors and returns an orthonormal basis for the space they span. We implement the *modified Gram-Schmidt* process, as it substantially reduces cumulative error.\n",
    "\n",
    "**Question 4** What does it mean for a set of vectors $v_1\\ldots,v_n$ to be *orthogonal*? What does it mean for them to be *orthonormal*?\n",
    "\n",
    "**Question 5** Consider the following pseudocode for the Gram-Schmidt (GS) and Modified Gram-Schmidt (MGS) algorithms for a set of *n* column vectors in an array *A*:\n",
    "> ###### Gram-Schmidt\n",
    "> $B = A$<br>\n",
    "> for $j = 1\\ldots n$:<br>\n",
    ">   for $k = 1\\ldots (j−1)$:  \n",
    ">      $B_j = B_j − proj_{B_k}(A_j)$<br>\n",
    ">    $B_j = B_j / |B_j|$  \n",
    "> return B\n",
    "\n",
    "\n",
    "> ###### Modified Gram-Schmidt\n",
    "> $B = A$<br>\n",
    "> for $j = 1\\ldots n$:<br>\n",
    ">   $\\hspace{0.175in}B_j = B_j / |B_j|$<br>\n",
    ">   for $k = (j+1)\\ldots n$:  \n",
    ">      $B_k = B_k − proj_{B_j}(B_k)$<br>\n",
    "> return B\n",
    "\n",
    "($A_j$ denotes the $j^{th}$ column of *A*, $|A_j|$ denotes its norm, and $A_j\\cdot B_k$ denotes the dot product.)\n",
    "\n",
    "By carrying out both procedures by hand on a matrix with three columns, explain the difference between the two in words. On the homework you will see the difference in a computational context.\n",
    "\n",
    "**Question 6** Write a function `ModGramSchmidt(A)` that takes a matrix $A$ and returns a matrix whose columns form an orthonormal basis for $C(A)$ using MGS. Since we insert any set of vectors as columns of a matrix, this implements Modified Gram-Schmidt. Test your code by showing that the vectors that result are orthonormal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7** The function you wrote in the previous question computes the *Q* in the QR decomposition. Write a `QR(A)` function that returns both *Q* and *R*. Test your code. Importantly, do not generate *R* using a matrix multiplication, as this is inefficient: Note that you are very likely computing the entries of *R* as you compute *Q*! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using QR for Least Squares\n",
    "\n",
    "**Question 8** Recall that the *least-squares* solution for $Ax=b$ is the solution to the *normal equation* $A^TAx=A^Tb$. Suppose we have a QR decomposition $A=QR$. By substituting this last equation into the normal equation, show that the least squares solution is the solution to $Rx=Q^Tb$. What property of $R$ allows this equation to be solved by back-substitution?\n",
    "\n",
    "**Question 9** Write a function called `QRLeastSquares(A,b)` that takes a matrix $A$ and a vector $b$, and returns the least squares solution to $Ax=b$ using QR decomposition and back-substitution. Test your function by recomputing the best fit line from Question 6 from Lab 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to Machine Learning\n",
    "\n",
    "### What is Machine Learning?\n",
    "\n",
    "In this lab, we are looking at *supervised machine learning*. In this paradigm, we *train* a *classifier* on a *training set* from the data, for which labels are known. We then *test* the classifier on the rest of the data. In the example above, you used least squares to train the classifier - an affine function with unknown parameters. Discovering the 'best' values for the parameters is the *training*. *Testing* would involve taking a unknown point and seeing the performance of your classifier. That is, experimentally finding the error rate. On the homework, you will compute theoretical error rates for your classifier. In practice, this is rarely possible.\n",
    "\n",
    "## Handwriting Recognition\n",
    "\n",
    "In the *data* folder, you will find files named *train-images-idx1-ubyte* and *train-labels-idx1-ubyte*. These files consist of 60,000 grayscale images of handwritten digits and labels for them. Each image is a $28\\times28$ array of values between 0 and 255. Each number represents how gray that pixel is, where 0 is black and 255 is white. A set of functions designed to read this data into arrays is provided in the file *MNISTHandwriting.ipnyb*.\n",
    "\n",
    "**Note:** The data comes from the MNIST Handwritten Digit Database. The original files and a lot of information about them can be found [here](http://yann.lecun.com/exdb/mnist/ \"MNIST Database\").\n",
    "\n",
    "To run the file referenced above, and read the images and their labels into arrays, use the following code:\n",
    "```python\n",
    "from MNISTHandwriting import readimgs\n",
    "images = readimgs('./data/train-images-idx3-ubyte')[0].astype('float')\n",
    "labels = readimgs('./data/train-labels-idx1-ubyte')[0].astype('float')\n",
    "```\n",
    "\n",
    "**Note:**  The readimgs command also returns the number of row and columns in each image, these are elements 1 and 2 of the array respectively. Feel free to read the code of the readimgs command! It contains some ideas that may be useful in your work. Note also that we cast the arrays to floats. The image data is in 8-bit integers for compactness reasons, but we will need floats in order to do any manipulation of the sort we need.\n",
    "\n",
    "**Question 10** \n",
    "1. After running the above, the following code will display image number 10400 and its label. Display a few images and their labels to get a feel for the data.\n",
    "\n",
    "```python\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(images[10400])\n",
    "labels[10400]\n",
    "```\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;2. What is the shape of the images array? (Hint: use `np.shape(A)` or `A.shape`) Can you explain why this makes sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from MNISTHandwriting import readimgs\n",
    "import numpy as np\n",
    "images = readimgs('./data/train-images-idx3-ubyte')[0].astype('float')\n",
    "labels = readimgs('./data/train-labels-idx1-ubyte')[0].astype('float')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(images[503])\n",
    "labels[503]\n",
    "\n",
    "print(np.shape(images))\n",
    "print(images)\n",
    "#This is the shape of our images array because we have 60000 different images, each of which is a 28 by 28 pixeled image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our strategy to label each image as being a zero or not a zero will be as follows:\n",
    "\n",
    "* Consider each image as a vector in $\\mathbb{R}^{28\\times28}=\\mathbb{R}^{784}$. <br><br>\n",
    "* Remove all vector elements corresponding to pixels that are black in all 60,000 images, as these pixels provide no useful data to distinguish between digits. This will reduce the dimension in which the images live. <br><br>\n",
    "* Use the label data to read off which images correspond to 0 and which don't. Use that to construct a vector consisting of just 1's and -1's, just like we did with the cluster above. <br><br>\n",
    "* Use least-squares to train an affine model. <br><br>\n",
    "* Decide how to use the model to test an image (like in Question 15 from Lab 6 and Question 3 from the homework). <br><br>\n",
    "* Test our model on another 10,000 images provided in the MNIST database.\n",
    "\n",
    "**Question 11 -- From $28\\times28$ to $784$** We want each image to be a vector in $\\mathbb{R}^{784}$. Right now, each image is a square of dimension $28\\times28$. The easiest way to do this is just to take the second row of pixels and join to the first, then the third to that, and so on until the 28th. Use the `np.reshape(A,(m,n))` command to do this. (Hint: you can do it with one `np.reshape` - no loops!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "newimage =np.reshape(images,(60000,784))\n",
    "print(newimage.shape)\n",
    "#plt.imshow(newimage[503])\n",
    "#**figure out how to make this get rid of the 1 here. \n",
    "#newimage = np.reshape(newimage,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12 -- Removing Common Black Pixels** Now that we've flattened our images, we want to find all columns in the array whose elements are all zero. Look back at the first lab and its homework to do this (again: no loops!). You want two outputs: the list of non-zero columns, and the array containing only those columns. You should find 717 non-zero columns. \n",
    "\n",
    "Lastly, create an array of size $60,000\\times 718$, the first 717 columns of which are the non-zero ones above, and the last a column of ones. We will use this to do least squares in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717\n",
      "[ 12  13  14  15  32  33  34  35  36  37  38  39  40  41  42  43  44  45\n",
      "  46  47  48  49  50  51  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  73  74  75  76  77  78  79  80  81  86  87  88  89  90  91\n",
      "  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129\n",
      " 130 131 132 133 134 135 136 137 138 139 142 143 144 145 146 147 148 149\n",
      " 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167\n",
      " 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186\n",
      " 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222\n",
      " 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240\n",
      " 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258\n",
      " 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276\n",
      " 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294\n",
      " 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312\n",
      " 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330\n",
      " 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348\n",
      " 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366\n",
      " 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384\n",
      " 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402\n",
      " 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420\n",
      " 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438\n",
      " 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456\n",
      " 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474\n",
      " 475 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493\n",
      " 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511\n",
      " 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529\n",
      " 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547\n",
      " 548 549 550 551 552 553 554 555 556 557 558 559 561 562 563 564 565 566\n",
      " 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584\n",
      " 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602\n",
      " 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620\n",
      " 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638\n",
      " 639 640 641 642 643 646 647 648 649 650 651 652 653 654 655 656 657 658\n",
      " 659 660 661 662 663 664 665 666 667 668 669 670 674 675 676 677 678 679\n",
      " 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697\n",
      " 698 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718\n",
      " 719 720 721 722 723 724 725 726 731 732 733 734 735 736 737 738 739 740\n",
      " 741 742 743 744 745 746 747 748 749 750 751 752 753 760 761 762 763 764\n",
      " 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thing = newimage.sum(axis=0)\n",
    "nozero = np.nonzero(thing)[0]\n",
    "#print(D)\n",
    "print(len(nozero))\n",
    "print(nozero)\n",
    "print(newimage[:,nozero])\n",
    "A = np.ones((60000,718))\n",
    "A[:,:717] = newimage[:,nozero]\n",
    "\n",
    "#array[:, [i, j]] helps you get the columns for the array of indices we have.\n",
    "#cols = newimage[:,nozero]\n",
    "#print(np.average(cols, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 13 -- Constructing the Ideal Output Vector** Note that the *labels* vector contains the 'correct' label for each of the 60,000 images. Use it to construct a second vector, one which has $1$ for every image labeled 0, and $-1$ for all others. Again, you can do this using logical indexing rather than loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 0. 4. ... 5. 6. 8.]\n",
      "[-1  1 -1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(labels)\n",
    "print(2*(labels==0)-1)\n",
    "newlabels = 2*(labels==0)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 14 -- Training the Model** We want to find the least squares solution $\\hat{x}$ to the matrix equation $Ax=v$, where $A$ is our filtered images matrix from Question 12, and $v$ is our idealized output vector from Question 13. As we did above, we do this by solving the normal equation $A^TAx=A^Tv$. \n",
    "\n",
    "* What is the size of the matrix $A^TA$?\n",
    "\n",
    "Above, we solved the normal equations using LU or QR decomposition code. This would work just fine here, but given the size of our matrices, will take a very long time. We'd also have to deal with small errors, something we haven't done before.  Instead, we will use a built-in function to do least squares. \n",
    "\n",
    "The `np.linalg.lstsq(A,v,rcond=tol)[0]` command  returns the least squares solution $\\hat{x}$ to $Ax=v$, where any number less than *tol* is treated as zero. For our purposes, a tolerance of $10^{-10}$ will be great. For convenience, run `import numpy.linalg as LA`, then reference the above command as `LA.lstsq(A,v,rcond=tol)[0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the matrix is 718 x 718."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 10**(-10)\n",
    "import numpy.linalg as LA\n",
    "sol = LA.lstsq(A,newlabels,rcond=tol)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the vector $\\hat{x}$ gives the coefficients $a_1,\\ldots,a_n,a_{n+1}$ of the affine function \n",
    "\n",
    "$$f(x_1,\\ldots,x_n) = a_1 x_1 + a_2x_2 + \\ldots +a_nx_n + a_{n+1}.$$ \n",
    "\n",
    "In our case, $n=717$. *Evaluating* our model on a given image means computing the value of this function on every image (that is, every ~~column~~ row of our images matrix). \n",
    "\n",
    "**Question 15 -- How to Use the Model** \n",
    "* How can you evaluate the model on all images with one command? (Hint: matrix multiplication!)\n",
    "* If an image vector evaluates to a number greater than or equal to 0, we'll label it as being a zero. If it maps to a number less than or equal to 0, we'll label it as being non-zero. Use logical indexing to write code that evaluates your model on all images, then creates a *modelresults* vector that is 1 if the model thinks you have a zero, and -1 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.82711851  0.77376361 -1.14818886 ... -1.09885844 -0.79512622\n",
      " -0.54558804]\n",
      "[-1  1 -1 ... -1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "bhat = A @ sol\n",
    "print(bhat)\n",
    "modelresults = 2*(bhat >0)-1\n",
    "print(modelresults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 16 -- The Expected Error Rate of the Model** We'll test the model in two parts: first, we'll see what the error rate is on the training set we used to train the model. This will give us an *expected* error rate. To test on the training set, all we need to do is find where our results match our ideal output vector. Note that for two arrays *A* and *B* of the same shape, the code `A==B` returns an array of the same shape, with zeros for entries where A does not equal B, and ones for entries where it does. Use this to compute the expected error rate as a decimal or a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True ...  True  True  True]\n",
      "934\n",
      "0.015566666666666666\n"
     ]
    }
   ],
   "source": [
    "print(newlabels == modelresults)\n",
    "print(60000-np.sum(newlabels == modelresults))\n",
    "print(934/60000)\n",
    "#1.49% error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 17 -- Testing on New Images** To test on a new set of images, note that the files *t10k-images-idx3-ubyte* and *t10k-labels-idx1-ubyte* in the *data* subfolder contain 10,000 images and labels in the same format as our training set. Use code similar to what we used above to read the images and the labels, then create an ideal output vector from the labels. **Be sure to remove the same rows from your new image array as the rows you removed in the training set! That is, do NOT find all-black pixels again!** Once you've done that, apply the model you got above to this new set of images and compute your error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.11"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def findnum (imagefile,labelfile,num):\n",
    "    from MNISTHandwriting import readimgs\n",
    "\n",
    "    images = readimgs('./data/'+ imagefile)[0].astype('float')\n",
    "    labels = readimgs('./data/'+ labelfile)[0].astype('float')\n",
    "    total, pix, pix= np.shape(images)\n",
    "    newimage =np.reshape(images,(total,pix*pix))\n",
    "    thing = newimage.sum(axis=0)\n",
    "    nozero = np.nonzero(thing)[0]\n",
    "    A = np.ones((total,len(nozero)+1))\n",
    "    A[:,:len(nozero)] = newimage[:,nozero]\n",
    "    newlabels = 2*(labels==num)-1\n",
    "    sol = LA.lstsq(A,newlabels,rcond=10**(-10))[0]\n",
    "    \n",
    "    bhat = A @ sol\n",
    "    modelresults = 2*(bhat >0)-1\n",
    "    error = total-np.sum(newlabels == modelresults)\n",
    "    return(error*100/total)\n",
    "       \n",
    "findnum('t10k-images-idx3-ubyte', 't10k-labels-idx1-ubyte',0)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

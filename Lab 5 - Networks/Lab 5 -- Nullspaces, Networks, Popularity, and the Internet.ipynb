{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity Matrices and Google PageRank\n",
    "\n",
    "In this section, we will define a notion of *popularity* in a social group. We will then see that the same notion can be applied to ranking web pages. In fact, a relatively small modification is exactly what Google uses when returning search results!\n",
    "\n",
    "> ## Make a copy of this notebook (File menu -> Make a Copy...)\n",
    "\n",
    "### Popularity in Social Groups\n",
    "\n",
    "Suppose we want to figure out how popular each person in a group of friends is. We could start by asking each person to list their friends and creating a 0-1 matrix of friendships. Some people will list everyone they know, and some will only list close friends, so it is not always the case that if $A$ is friends with $B$, then $B$ is friends with $A$.\n",
    "\n",
    "Let's start with a group of five people, labeled A, B, C, D, and E. We get the following data:\n",
    "* A lists B, and E;\n",
    "* B lists A, C, D, and E;\n",
    "* C lists A, B, and E;\n",
    "* D lists B, and C;\n",
    "* E lists A, B, and D.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.25       0.33333333 0.         0.33333333]\n",
      " [0.5        0.         0.33333333 0.5        0.33333333]\n",
      " [0.         0.25       0.         0.5        0.        ]\n",
      " [0.         0.25       0.         0.         0.33333333]\n",
      " [0.5        0.25       0.33333333 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rref import rref \n",
    "A = np.array([[0,.25,1/3,0,1/3],[.5,0,1/3,.5,1/3],[0,.25,0,.5,0],[0,.25,0,0,1/3],[.5,.25,1/3,0,0]])\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1** Write down a $5\\times 5$ matrix of zeros and ones incorporating this data. Label the rows and columns A-E, and put a 1 in position $(i,j)$ if the person in column $j$ lists the person in row $i$. This is called an *adjacency matrix*.\n",
    "\n",
    "A person's popularity comes from other people they are friends with. For example, $A$ lists two people: $B$ and $E$, so they contribute $\\frac12$ of their popularity to $B$ and $\\frac12$ to $E$. We therefore define a person's *popularity* to be a weighted average of the popularities of the people who list them. If we denote A's popularity by $P_A$, then we get $$P_A = \\frac14 P_B + \\frac13 P_C + \\frac13 P_E.$$\n",
    "\n",
    "**Question 2** Write down the other four equations for the popularity of persons B through E. Then rewrite your equations as a matrix equation. We will call the matrix in this equation a *popularity matrix*.\n",
    "\n",
    "**Question 3** What is the relation between the matrix in Question 1 and the matrix in Question 2? Describe how to get from an adjacency matrix to a popularity matrix.\n",
    "\n",
    "Note that the sums of each column in your matrix is 1. Such a matrix is called a *Markov* matrix (also called a *column stochastic* matrix). You will encounter such matrices often, especially in probability classes.\n",
    "\n",
    "Your equation is different from previous simultaneous equations you have seen in that the variables appear on both sides. If we let $v=\\begin{bmatrix}P_A & P_B & P_C & P_D & P_E \\end{bmatrix}^T$, then we have $$Av=v.$$\n",
    "\n",
    "So if we found numerical solutions for each of the popularities, multiplying the matrix by a vector composed of them would result in the same vector. Let's rearrange: $$\\begin{align*} ~&Av  =  v \\\\ \\Leftrightarrow & Av-v  =  0 \\\\ \\Leftrightarrow & Av-Iv = 0 \\\\ \\Leftrightarrow & (A-I)v=0\\end{align*}$$\n",
    "\n",
    "**Question 4** Write your matrix equation above in this new form.\n",
    "\n",
    ">**This is a *homogenous* system of equations written in matrix form. Be sure you know what *homogenous* means in this context!**\n",
    "\n",
    "**Question 5** Can you write down a trivial solution for this equation? Why is this solution not interesting to us?\n",
    "\n",
    "As you have discussed in class, one way to solve homogenous equations is to reduce the matrix to *row-reduced echelon form*. We have not written code to do this. While it is not incredibly difficult to do so (an algorithm is given [here](https://www.math.purdue.edu/~shao92/documents/Algorithm%20REF.pdf)), it requires programming techniques a little more advanced than what we have covered. Rather than asking you to write the code, it is provided in the *rref.py* file, from which you can import it.\n",
    "\n",
    "Due to numerical precision issues, it is essential to have our row-reduction code have a *tolerance*. That is, a number below which it will assume a given entry is zero. We will take our tolerance to be $10^{-10}$. To run the row-reduction code on a matrix A:\n",
    "```python\n",
    "from rref import rref\n",
    "rref(A,10**-10)\n",
    "```\n",
    "\n",
    "The ```rref``` code has been written so that $10^{-10}$ is a default, so you can also call it as ```rref(A)``` unless you need to change the tolerance for some reason.\n",
    "\n",
    "**Question 6** Run this code to find the row-reduced echelon form of $A-I$. Then answer the following:\n",
    "1. Rewrite your matrix equation in the reduced form. <br><br>\n",
    "1. Why is there an infinite number of solutions to the equation $Av=v$? <br><br>\n",
    "1. If we arbitrarily assign person E a popularity score of 1, what are all the other people's popularities?<br><br>\n",
    "1. It might be tempting to say that a person's popularity is simply the number of people who list them (or is at least proportional to it). But this is not the case: A and E were each listed by three other people, but have different popularity scores. Can you explain why?<br><br>\n",
    "1. What is the dimension of the nullspace of $A-I$?<br><br>\n",
    "1. If $v$ is a solution of of $Av=v$, then so is $tv$ for any scalar $t$ (make sure you understand why). Suppose we wanted the sum of our poularities to add up to exactly $1$. How could you choose $t$ to ensure this? To three decimal places, write down the popularity vector that results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.25       0.33333333 0.         0.33333333]\n",
      " [0.5        0.         0.33333333 0.5        0.33333333]\n",
      " [0.         0.25       0.         0.5        0.        ]\n",
      " [0.         0.25       0.         0.         0.33333333]\n",
      " [0.5        0.25       0.33333333 0.         0.        ]]\n",
      "[[ 1.          0.          0.          0.         -0.88888889]\n",
      " [-0.          1.          0.          0.         -1.33333333]\n",
      " [-0.         -0.          1.          0.         -0.66666667]\n",
      " [-0.         -0.         -0.          1.         -0.66666667]\n",
      " [ 0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from rref import rref \n",
    "A = np.array([[0,.25,1/3,0,1/3],[.5,0,1/3,.5,1/3],[0,.25,0,.5,0],[0,.25,0,0,1/3],[.5,.25,1/3,0,0]])\n",
    "print(A)\n",
    "I = np.identity(5)\n",
    "#2. Here, we can see that there are clearly an infinite number of solutions because there is a free variable, E, that ensures that there are infinite solutions.\n",
    "#   There are an infinite number of solutions because we can just use scalar multiples of v that still find the same solution.\n",
    "#3. If we set E to 1, then this means that some linear combination of 0.5 + 0.25+ 0.333333 is equivalent to 1. \n",
    "#   Pa = 0.88888 ; Pb = 1.333333; Pc = 1.666666; Pd = 0.666666; Pe = 1.\n",
    "#4. This is because each individual's popularity score is weighted differently based on how popular the people who list them are.\n",
    "#5. The dimension of the null space of A-I is going to be 1.\n",
    "#6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is tempting at this point to say that the popularity vector is simply a basis vector for the nullspace of $A-I$, where $A$ is a popularity matrix. However, we need to question some assumptions:\n",
    "\n",
    "**Question 7** What are we assuming about the nullspace of $A-I$ in making the above statement? (Hint: see part 5 of the previous question!)\n",
    "\n",
    "In fact, our assumptions are true for certain classes column stochastic matrices, called *regular* matrices. This follows from the **Perron-Frobenius Theorem**. The proof of this is difficult and beyond the scope of this class, but it is a remarkably useful result. In fact, Google founders Larry Page and Sergey Brin used exactly this theorem when they first came up with PageRank, the search result ranking algorithm that made Google the most famous company in the world. In the next section, we examine a version of PageRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Within this matrix, we are assuming that the null space has only one dimension; that it only has one vector within its span. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google PageRank\n",
    "\n",
    "A very similar idea to popularity matrices underlies Google PageRank. Consider the following small set of web pages, with arrows indicating links. An arrow from web page A to web page B indicates that A links to B.\n",
    "\n",
    "![](img/lab4network1.png)\n",
    "\n",
    "We can think of one web page linking to another as equivalent to listing it as a friend when thinking about popularity matrices. In this context, we will call this matrix the *link matrix* of the network.\n",
    "\n",
    "**Question 8** Write down the link matrix $A$ for the above network and compute a vector $v$ such that $Av=v$ using the `rref(A)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.          0.         -2.        ]\n",
      " [-0.          1.          0.         -0.66666667]\n",
      " [-0.         -0.          1.         -1.5       ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "[2.         0.66666667 1.5        1.        ]\n"
     ]
    }
   ],
   "source": [
    "A1 = np.array([[0,0,1,.5],[1/3,0,0,0],[1/3,.5,0,.5],[1/3,.5,0,0]])\n",
    "I = np.identity(4)\n",
    "print(rref(A1-I))\n",
    "A1 = rref(A1-I)\n",
    "# set D to 1.\n",
    "v = A1[:,3]\n",
    "v = -v\n",
    "v[3] = 1\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the *PageRank vector* of a link matrix $A$ as the unique vector $v$ that solves $Av=v$ and whose sum of entries is one.\n",
    "\n",
    "**Question 9** Compute the PageRank vector for the above network. (See your answer to the last part of Question 6 above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38709677 0.12903226 0.29032258 0.19354839]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "v = v/(np.sum(v))\n",
    "print(v)\n",
    "print(np.sum(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10** Write a function called `pagerank(A)` that takes a link matrix and returns the PageRank vector. Your function should use the `rref(A)` function. Note that the last column of the row-reduced echelon form matrix is closely related to the vector you seek. If you don't rememeber how to get the last column of a matrix, look back at the very first lab! Test your function on the matrix from Question 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38709677 0.12903226 0.29032258 0.19354839]\n"
     ]
    }
   ],
   "source": [
    "def pagerank(A):\n",
    "    rows = A.shape[0]\n",
    "    I = np.identity(rows)\n",
    "    newA = rref(A-I)\n",
    "    v = newA[:,rows-1]\n",
    "    v = -v\n",
    "    v[rows-1] = 1\n",
    "    v = v/(np.sum(v))\n",
    "    return v\n",
    "A = np.array([[0,0,1,.5],[1/3,0,0,0],[1/3,.5,0,.5],[1/3,.5,0,0]])\n",
    "print(pagerank(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So that's it, right? We have Google's PageRank! Or maybe not...\n",
    "\n",
    "#### First Problem: Dangling Nodes\n",
    "\n",
    "**Question 11** Write down the link matrix $A$ for the following network:\n",
    "\n",
    "![](img/lab4network2.png)\n",
    "\n",
    "\n",
    "1. Why will the ideas above not work for this matrix? (Hint: see the text under question 7.)<br><br>\n",
    "1. What is the row-reduced echelon form of $A-I$?<br><br>\n",
    "1. Find a basis for the nullspace of $A-I$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  0.  0.]\n",
      " [ 0. -1.  0.]\n",
      " [ 1.  1. -1.]]\n",
      "[[ 1.  0.  0.]\n",
      " [-0.  1.  0.]\n",
      " [-0. -0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,0,0],[0,0,0],[1,1,0]])\n",
    "#This doesn't work for this matrix because it only works for so-called \"regular matrices\" that have non-zero values in every row.\n",
    "#Also, it's because it is assumed in our algorithm that each node is also linked to other nodes other than itself, which is not the case here.\n",
    "I = np.identity(3)\n",
    "print(A-I)\n",
    "print(rref(A-I))\n",
    "#The basis for the nullspace of A - I is simply an empty basis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem arises if we have *dangling nodes*. That is, pages that have no outgoing links. That results in the link matrix not being Markov, so Perron-Frobenius does not apply. \n",
    "\n",
    "**Question 12** One workaround is simply to declare that all nodes have equal influence on node $C$, so that its column becomes ${\\large[} \\frac13  \\frac13  \\frac13 {\\large]}^T$. Try this out. It is part of the approach Google uses. We will get back to that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.          0.          0.33333333]\n",
      " [ 0.         -1.          0.33333333]\n",
      " [ 1.          1.         -0.66666667]]\n",
      "[[ 1.          0.         -0.33333333]\n",
      " [-0.          1.         -0.33333333]\n",
      " [ 0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,0,1/3],[0,0,1/3],[1,1.,1/3]])\n",
    "I = np.identity(3)\n",
    "print(A-I)\n",
    "print(rref(A-I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Problem: Disconnected Networks\n",
    "\n",
    "**Question 13** By analyzing the link matrix $A$ for the following network, explain why our method above won't work here either. (Hint: Compute the dimension of the nullspace of $A-I$?)\n",
    "\n",
    "![](img/lab4network3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.   1.   0.   0.   0. ]\n",
      " [ 1.  -1.   0.   0.   0. ]\n",
      " [ 0.   0.  -1.   0.5  0.5]\n",
      " [ 0.   0.   0.5 -1.   0.5]\n",
      " [ 0.   0.   0.5  0.5 -1. ]]\n",
      "[[ 1. -1.  0.  0. -0.]\n",
      " [-0. -0.  1.  0. -1.]\n",
      " [-0. -0. -0.  1. -1.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,1,0,0,0],[1,0,0,0,0],[0,0,0,.5,.5],[0,0,.5,0,.5],[0,0,.5,.5,0]])\n",
    "I = np.identity(5)\n",
    "print(A-I)\n",
    "print(rref(A-I))\n",
    "#There are 2 free variables in the nullspace of A - I (dim = 2), which is not ideal; we want to be able to parameterize the probabilities by only a single free variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, our `pagerank(A)` function will only work for connected networks with no dangling nodes. Given that the web is unlikely to be connected, and that there are definitely dangling nodes, it is clear that our methods are insufficient. Before we get to how Google solves this problem, let's take a different point of view on our link matrices.\n",
    "\n",
    "### A Probablistic Approach\n",
    "\n",
    "Going back to the first network we dealt with, we see that there are four nodes, that the network is connected, and that none of the nodes are dangling. Let's consider a vector $v_0$ with four entries, one for each node, giving the probability that a user is looking at that web page at a given time. Suppose for the moment that the user is equally likely to start at any page. Therefore, $$v_0=\\left(\\begin{smallmatrix} 0.25 \\\\ 0.25 \\\\ 0.25 \\\\ 0.25\\end{smallmatrix}\\right)$$\n",
    "\n",
    "Suppose also that the user is equally likely to click on any link on the page they are on.\n",
    "\n",
    "**Question 14** \n",
    "1. What is the probability that after one click, the user is on page A? What about B, C, and D?<br><br>\n",
    "1. If you look at your calculations carefully, you should be able to write $v_1$, the vector of probabilities that the user is on a given page after one click, in terms of the link matrix for the network and the vector $v_0$. Do so.<br><br>\n",
    "1. Can you write an expression for $v_k$, the vector of probabilities that the user is on a given page after $k$ clicks?<br><br>\n",
    "1. Using `np.linalg.matrix_power(A,p)` to compute matrix powers, compute $v_{20}$. Compare your answer to the result from Question 9.<br><br>\n",
    "1. Suppose that page A is the user's home page, so that they always start there. What is $v_0$ in this case? Compute $v_{20}$ given this $v_0$.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         1.         0.5       ]\n",
      " [0.33333333 0.         0.         0.        ]\n",
      " [0.33333333 0.5        0.         0.5       ]\n",
      " [0.33333333 0.5        0.         0.        ]]\n",
      "[0.38709616 0.12903205 0.29032302 0.19354877]\n",
      "[0.38709367 0.12903452 0.29032216 0.19354965]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,0,1,.5],[1/3,0,0,0],[1/3,.5,0,.5],[1/3,.5,0,0]])\n",
    "print(A)\n",
    "#1. Probability is .25 for each page.\n",
    "v0 = np.array([.25,.25,.25,.25])\n",
    "v1 = A*v0\n",
    "k = 20\n",
    "vk = np.linalg.matrix_power(A,k) @ v0\n",
    "print(vk)\n",
    "# These are the same values.\n",
    "v0 = np.array([1,0,0,0])\n",
    "k = 20\n",
    "vk = np.linalg.matrix_power(A,k) @ v0\n",
    "print(vk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 15** Suppose that $v$ is the PageRank vector for a network whose link matrix is given by $A$, as defined in the previous section, that $v_0$ is any probability vector (a vector whose components sum to 1). Then from the last question, it seems that $$v=\\lim_{k\\to\\infty} A^k \\times v_0.$$\n",
    "\n",
    "In fact, the **Power Iteration Theorem** says that this is true under much the same conditions that Perron-Frobenius is. In other words, when a unique solution with sum 1 to $Av=v$ exists, we can characterize it as the vector giving the probabilities that the user will end up at a given node after a long time spent clicking.\n",
    "\n",
    "**Question 16** Try to use this method to find $v$ for the second and third networks above. What goes wrong? (Hint for the third network: try making the user's homepage A, then C. For A, try different matrix powers.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19993985 0.19993985 0.60012029]\n",
      "[0.5        0.         0.16666698 0.16666651 0.16666651]\n"
     ]
    }
   ],
   "source": [
    "A1 = np.array([[0,0,1/3],[0,0,1/3],[1,1,1/3]])\n",
    "A2 = np.array([[0,1,0,0,0],[1,0,0,0,0],[0,0,0,.5,.5],[0,0,.5,0,.5],[0,0,.5,.5,0]])\n",
    "v1 = np.array([0,0,1])\n",
    "v2 = np.array([.5,0,.5,0,0])\n",
    "k = 20\n",
    "vk1 = np.linalg.matrix_power(A1,20) @ v1\n",
    "vk2 = np.linalg.matrix_power(A2,20) @ v2\n",
    "print(vk1)\n",
    "print(vk2)\n",
    "#Here, the second matrix here is stating that it is essentially impossible for the first two sites, A and B, to be reached.\n",
    "#This is because when we ensure that the user starts at either A or C, both of which are independently connected to other sites, \n",
    "#we ensure that there is no way for the user to reach the other websites that are not linked to the one the user starts on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from the probabilistic point of view, the issue with a disconnected network is that the probability of ending up in a given node after a lot of clicking depends on which part of the network you start in. In other words, there cannot be a single vector giving these probabilities. Indeed, as you saw in Question 12, there is not a single unique solution with sum 1 for a disconnected network.\n",
    "\n",
    "### Google's Solution\n",
    "\n",
    "When browsing the web, we often click from page to page. However, once a while we just go to a totally new page without clicking a link. Suppose that at any given point in time, the probability of this is some number $0<p<1$. If $A$ is the link matrix of a network, Google defines the *PageRank* matrix of a network with $n$ nodes to be $$P=(1-p)A + pB\\mbox{, where } B=\\frac{1}{n}\\begin{bmatrix} 1 & 1 & \\dots & 1 \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ 1 & 1 & 1 & 1\\end{bmatrix}$$\n",
    "\n",
    "Suppose that $p=0.15$. Then 85% of the time, the user clicks on links, so the matrix $A$ governs their behavior. The other 15% of the time, the user picks another page at random (all pages have equal probability), so the matrix $B$ governs their behavior. Make sure you understand this!\n",
    "\n",
    "As you will see on the homework, the matrix $P$ is always Markov when $A$ is, and all the entries of $P^k$ are positive for positive integers *k*. Happily, these are exactly conditions under which the Perron-Frobenius and Power Iteration theorems are true!\n",
    "\n",
    "Lastly, we need to fix the issue with dangling nodes (and thus ensure that $A$ is Markov). Google does this by assuming that at any point in time, if a user is on a page with no outgoing links, they have an equal probability of jumping to any other page. So before we add the matrix $pB$ above, we replace any zero column in our matrix $A$ with a column of equal entries.\n",
    "\n",
    "We redefine the *PageRank vector with damping factor $p$* to be the unique solution with sum 1 of $Pv=v$, where the $P$ is the PageRank matrix as defined above. Note that our previous PageRank vector is the one corresponding to damping factor 0.\n",
    "\n",
    "**Question 17** Assuming that $p=0.15$, calculate the PageRank matrices for each of the networks above. Be sure to replace any zero columns with a column of equal entries first! Then use both the row reduction and the power iteration methods to calculate their PageRank vectors. Comment on your results for the second and third networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0375     0.0375     0.8875     0.4625    ]\n",
      " [0.32083333 0.0375     0.0375     0.0375    ]\n",
      " [0.32083333 0.4625     0.0375     0.4625    ]\n",
      " [0.32083333 0.4625     0.0375     0.0375    ]]\n",
      "[[0.05       0.05       0.33333333]\n",
      " [0.05       0.05       0.33333333]\n",
      " [0.9        0.9        0.33333333]]\n",
      "[[0.03  0.88  0.03  0.03  0.03 ]\n",
      " [0.88  0.03  0.03  0.03  0.03 ]\n",
      " [0.03  0.03  0.03  0.455 0.455]\n",
      " [0.03  0.03  0.455 0.03  0.455]\n",
      " [0.03  0.03  0.455 0.455 0.03 ]]\n",
      "\n",
      "Row Reduction for networks 1-3:\n",
      "[0.36815068 0.14180936 0.28796163 0.20207834]\n",
      "[0.21276596 0.21276596 0.57446809]\n",
      "[0.2 0.2 0.2 0.2 0.2]\n",
      "\n",
      "Power Iteration for networks 1-3:\n",
      "[0.36815068 0.14180936 0.28796163 0.20207834]\n",
      "[0.21276596 0.21276596 0.57446809]\n",
      "[0.2 0.2 0.2 0.2 0.2]\n"
     ]
    }
   ],
   "source": [
    "#This is saying if p = 15, then we have 85% chance of clicking on another link in A, and 15% chance of going to a brand new page. \n",
    "A1 = np.array([[0,0,1,.5],[1/3,0,0,0],[1/3,.5,0,.5],[1/3,.5,0,0]])\n",
    "A2 = np.array([[0,0,1/3],[0.,0,1/3],[1,1,1/3]])\n",
    "A3 = np.array([[0,1,0,0,0],[1,0,0,0,0],[0,0,0,.5,.5],[0,0,.5,0,.5],[0,0,.5,.5,0]])\n",
    "p = 0.15\n",
    "P1 = (1-p) * A1 + .25*p*np.ones((4,4))\n",
    "P2 = (1-p) * A2 + (1/3)*p*np.ones((3,3))\n",
    "P3 = (1-p) * A3 + .2*p*np.ones((5,5))\n",
    "print(P1)\n",
    "print(P2)\n",
    "print(P3)\n",
    "print(\"\\nRow Reduction for networks 1-3:\")\n",
    "\n",
    "print(pagerank((P1)))\n",
    "print(pagerank((P2)))\n",
    "print(pagerank((P3)))\n",
    "\n",
    "print(\"\\nPower Iteration for networks 1-3:\")\n",
    "v1 = np.array([.25,.25,.25,.25])\n",
    "v2 = np.array([1/3,1/3,1/3])\n",
    "v3 = np.array([.2,.2,.2,.2,.2])\n",
    "#v3 = np.array([1,0,0,0,0])\n",
    "\n",
    "k = 401\n",
    "vk1 = np.linalg.matrix_power(P1,k) @ v1\n",
    "vk2 = np.linalg.matrix_power(P2,k) @ v2\n",
    "vk3 = np.linalg.matrix_power(P3,k) @ v3\n",
    "print(vk1)\n",
    "print(vk2)\n",
    "print(vk3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After replacing zero columns with the probability that each node has an equal influence on the column in question (ie 1/3, 1/3, 1/3), we can see that whether or not we use the row reduction or power iteration methods, we still return the same pagerank vector regardless."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalues, Eigenvectors, PageRank, and Markov Chains\n",
    "\n",
    "In this lab, we will use the concepts of eigenvectors and eigenvalues to explore ideas from probability. \n",
    "\n",
    "> ## Make a copy of this notebook (File menu -> Make a Copy...)\n",
    "\n",
    "## Pre-Lab\n",
    "\n",
    "Before this lab, you should review Lab 5. We will return to some of the ideas dicussed there and discuss them from a more sophisticated point of view.\n",
    "\n",
    "Recall that our popularity matrices from Lab 5 were square matrices whose column sums are all one (also known as *column-stochastic* matrices). Suppose that $P$ is a such a matrix. Then as we stated in that lab, the *Perron-Frobenius* theorem guarantees that the equation $Av=v$ has a solution.\n",
    "\n",
    "**Question 1** Restate this result regarding column stochastic matrices in terms of eigenvalues and eigenvectors.\n",
    "\n",
    "**Question 2** \n",
    "1. From Question 8 in Lab 5, write down the link matrix for the following small network of web pages:\n",
    "\n",
    "![](lab4network1.png)\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;2. Show by hand or by using row reduction code that the matrix has an eigenvalue of $1$. Find a corresponding eigenvector whose sum of entries is $1$. <br><br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;3. Show that the eigenvalue has a geometric multiplicity of 1 (number of associated eigenvectors). If you remember polynomial long division, show that its algebraic multiplicty is also 1 (number of times the eigenvalue is a root of the characteristic equation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         1.         0.5       ]\n",
      " [0.33333333 0.         0.         0.        ]\n",
      " [0.33333333 0.5        0.         0.5       ]\n",
      " [0.33333333 0.5        0.         0.        ]]\n",
      "[0.38709677 0.12903226 0.29032258 0.19354839]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[0,0,1,1/2],[1/3,0,0,0],[1/3,1/2,0,1/2],[1/3,1/2,0,0]])\n",
    "print(A)\n",
    "from rref import rref \n",
    "\n",
    "\n",
    "def pagerank(A):\n",
    "    rows = A.shape[0]\n",
    "    I = np.identity(rows)\n",
    "    newA = rref(A-I)\n",
    "    v = newA[:,rows-1]\n",
    "    v = -v\n",
    "    v[rows-1] = 1\n",
    "    v = v/(np.sum(v))\n",
    "    return v\n",
    "\n",
    "print(pagerank(A))\n",
    "print(np.sum(pagerank(A)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chains\n",
    "\n",
    "Consider a simple model for weather: the model accounts for three types of days - sunny, cloudy, and rainy. We want to make assumptions about tomorrow given the weather today. It's not unreasonable to say that is today is sunny, tomorrow is likely to be sunny, if today is cloudy, tomorrow is likely to be cloudy or rainy, and if today is rainy, tomorrow could be pretty much anything. To express this matematically, we will use the language of *conditional probability*. Let's say that if today is sunny, there's a $60\\%$ chance that tomorrow will also be sunny. We express this as follows:\n",
    "\n",
    "$$\\mathbb{P}(\\mbox{sunny tomorrow}|\\mbox{sunny today})=0.6$$\n",
    "\n",
    "Read this: the probability that tomorrow will be sunny, given that it is sunny today, is $0.6$.\n",
    "\n",
    "**Question 3** Some assumptions: \n",
    "* If it is sunny today, there's a $60\\%$ chance tomorrow will be sunny, a $30\\%$ chance tomorrow will be cloudy, and a $10\\%$ chance tomorrow will be rainy.\n",
    "* If it is cloudy today, there's a $20\\%$ chance tomorrow will be sunny, a $45\\%$ chance tomorrow will be cloudy, and a $35\\%$ chance tomorrow will be rainy.\n",
    "* If it is rainy today, there's a $30\\%$ chance tomorrow will be sunny, a $40\\%$ chance tomorrow will be cloudy, and a $30\\%$ chance tomorrow will be rainy.<br><br>\n",
    "Write these as conditional probabilities. Feel free to make up a shorthand.<br><br>\n",
    "\n",
    "We will find it useful to express these probabilities in a couple of different ways. The first is a *state space diagram*: we draw a node for each of the states (sunny, cloudy, rainy), and draw arrows between states if it is possible to transition between them. We then label each arrow with the correct probability.\n",
    "\n",
    "**Question 4** Copy the following state space diagram for the model above and label each of the arrows:\n",
    "\n",
    "![](img/lab9network1.png)\n",
    "\n",
    "The sum of the numbers on arrows coming out of any given node should be exactly 1. Why must this be true?<br><br>\n",
    "\n",
    "Another way to represent these probabilties is in a matrix. If there are $n$ states, we create an $n\\times n$ matrix. We label both the columns and the rows with the states. In the situation above, we think of the columns as 'today' and the rows as 'tomorrow'. We always use the same ordering for rows and columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6  0.2  0.3 ]\n",
      " [0.3  0.45 0.4 ]\n",
      " [0.1  0.35 0.3 ]]\n"
     ]
    }
   ],
   "source": [
    "weather = np.array([[0.6,0.2,0.3],[0.3,0.45,0.4],[0.1,0.35,0.3]])\n",
    "\n",
    "print(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "**Question 5** Suppose the first column and row are 'sunny today' and 'sunny tomorrow' respectively, the second are the cloudy days, and the third the rainy days. Write down the $3\\times 3$ matrix corresponding to the situation described above.<br><br>\n",
    "\n",
    "**Question 6** Compare the matrix you just wrote down to the link matrix from Question 2. Write down some similarities and differences. What property of this matrix corresponds to the idea that the sum of numbers out of each node in the state space diagram above is 1?\n",
    "\n",
    "### Understanding Conditional Probabilities\n",
    "\n",
    "For any two events $A$ and $B$, the following is true: \n",
    "\n",
    "$$\\mathbb{P}(A|B) = \\frac{\\mathbb{P}(A\\cap B)}{\\mathbb{P}(B)}$$\n",
    "\n",
    "We will try to clarify this by example referring to our model above: Let us denote the event that today is sunny by $S_0$, and that tomorrow is sunny by $S_1$. Likewise, denote cloudy and rainy day events. Then \n",
    "\n",
    "$$\\mathbb{P}(S_1|S_0) = \\frac{\\mathbb{P}(S_1\\cap S_0)}{\\mathbb{P}(S_0)}$$.\n",
    "\n",
    "Or, rearranging:\n",
    "\n",
    "$$\\mathbb{P}(S_1\\cap S_0) = \\mathbb{P}(S_0)\\mathbb{P}(S_1| S_0)$$\n",
    "\n",
    "Note that the probability on the left of this last equation is the probability of today being sunny *and* tomorrow being sunny.\n",
    "\n",
    "**Question 7**\n",
    "1. Suppose that today has a $1/3$ chance of being sunny. Given the model above, what is the probability that today and tomorrow will both be sunny?<br><br>\n",
    "1. Explain why the following must be true:\n",
    "\n",
    "$$\\mathbb{P}(S_1)=\\mathbb{P}(S_0)\\mathbb{P}(S_1| S_0) + \\mathbb{P}(C_0)\\mathbb{P}(S_1| C_0) + \\mathbb{P}(R_0)\\mathbb{P}(S_1| R_0)$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;3. Suppose today also has a $1/2$ chance of being cloudy, and a $1/6$ chance of being rainy. Calculate the probability that tomorrow is sunny.<br><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;4. Write similar equations for the probabilities of tomorrow being cloudy and of tomorrow being rainy, then calculate these probabilties.\n",
    "\n",
    "**Question 8** \n",
    "1. Rewrite down the matrix you wrote in Question 5 in terms of conditional probabilities. For example, the entry in the first row, first column will be $\\mathbb{P}(S_1|S_0)$.<br><br>\n",
    "1. Multiply your matrix by the column vector below and examine the result. Referring to Question 7, what have you calculated?\n",
    "\n",
    "$$\\left(\\begin{matrix}\\mathbb{P}(S_0) \\\\ \\mathbb{P}(C_0) \\\\ \\mathbb{P}(R_0)\\end{matrix}\\right)$$\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;3. In the code box below, carry out your calculation given our model and the probabilities from Question 7. Verify that you get the same answers.<br><br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;4. Next, compute the probabilties of the day *after tomorrow* being sunny, cloudy, and rainy.<br><br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;5. If we call our matrix $A$, and the vector of probabilities $p$, write down an expression for the probabilty vector of weather $n$ days from now.<br><br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;6. How would you compute a transition matrix from the state today to the state two days from now? Three days from now? $n$ days from now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6  0.2  0.3 ]\n",
      " [0.3  0.45 0.4 ]\n",
      " [0.1  0.35 0.3 ]]\n",
      "[0.35       0.39166667 0.25833333]\n",
      "[0.3740458  0.38167939 0.24427481]\n"
     ]
    }
   ],
   "source": [
    "weather = np.array([[0.6,0.2,0.3],[0.3,0.45,0.4],[0.1,0.35,0.3]])\n",
    "\n",
    "print(weather)\n",
    "v = np.array([1/3,0.5,1/6])\n",
    "print(weather@v)\n",
    "v0= weather@v\n",
    "A =np.linalg.matrix_power(weather,20)\n",
    "print(A@v0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of ways to find powers of matrices. In class, we will see how matrices are raised to powers when they can be *diagonalized*. For now, though, NumPy has a built-in function to do this:\n",
    "```python\n",
    "np.linalg.matrix_power(A,10)\n",
    "```\n",
    "computes $A^{10}$\n",
    "\n",
    "**Question 9** \n",
    "1. Assuming the same initial probability vector as before, calculate the probabilities of the weather events for the next 20 days. What do you notice?<br><br>\n",
    "1. Now start with a different initial vector: suppose that we know that today has a $90\\%$ chance of being sunny, and a $10\\%$ chance of being rainy. Compute our expectations for the next 20 days. What do you notice?<br><br>\n",
    "1. Experiment with some other initial vectors. What do you notice?<br><br>\n",
    "1. Consider the matrix $A^{20}$. What does it tell you? Compute it and examine it, comparing to the answer to the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57 0.31 0.12]\n",
      "[0.3740458  0.38167939 0.24427481]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([.9,0,.1])\n",
    "print(weather@v)\n",
    "v0= weather@v\n",
    "A =np.linalg.matrix_power(weather,20)\n",
    "print(A@v0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10** Assuming it exists and agrees with your observation above, what does the limit $\\displaystyle\\lim_{n\\to\\infty} A^n v$ mean?\n",
    "\n",
    "**Question 11** Making the same assumptions, denote the limit above by $\\hat{v}$. What can you say about $A\\hat{v}$? What does this imply about $\\hat{v}$ in terms of the matrix $A$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Definitions\n",
    "\n",
    "**Definition** A *Markov chain* is a sequence of possible events in which the probability of the next event depends solely on the state of the previous event.\n",
    "\n",
    "**Example** Our weather model is a Markov chain: the weather tomorrow only depends on the weather today, not on the weather yesterday or before.\n",
    "\n",
    "**Definition** If we have a Markov chain with transition matrix $A$, an eigenvector with eigenvalue $1$ is called a *stationary distribution* of the Markov chain. \n",
    "\n",
    "*Note: Since transition matrices are column stochastic, the Perron Frobenius theorem guarantees that $A$ has an eigenvalue of $1$. However, as we'll see below, its eigenspace may not be one dimensional.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Messier Markov Chains\n",
    "\n",
    "In a sense, our weather example above was an ideal example of a Markov chain: its transition matrix had an eigenvalue of $1$, the corresponding eigenspace was one dimensional (that is, there was a unique eigenvector wih sum 1), and $A^n v$ converged to that eigenvector as $n\\to\\infty$. In such cases, we can predict long-term behavior of the chain simply by finding the eigenvector corresponding to the eigenvalue of $1$. That allows us, for example, to predict how many days will be rainy, sunny, or cloudy overall. If all Markov chains behaved like this, we'd have a pretty easy time! Somewhat unsurprisingly, they don't...\n",
    "\n",
    "\n",
    "#### Disconnnected Markov Chains\n",
    "**Question 12** Consider a Markov chain with the following state space diagram\n",
    "\n",
    "![](img/lab9network2.png)\n",
    "\n",
    "  1. Without writing down the transition matrix $A$ or doing any calculations, explain why it is impossible for the limit $\\displaystyle\\lim_{n\\to\\infty} A^nv$ to be independent of the vector $v$. (Hint: Consider the following situations - knowing that you start in state 1; and knowing that you start in state 3.)<br><br>\n",
    "  1. Write down two initial vectors $v_1$ and $v_2$ for which you expect the limit above to be different. (Recall that all our vectors need to have a sum of $1$.)<br><br>\n",
    "  1. Write down the transition matrix for this Markov chain, and use the code box below to test out your hypothesis.  What are the two limiting vectors (a.k.a. stationary distributions)?<br><br>\n",
    "  1. Show (by hand or using row-reduction functions) that your transition matrix has an eigenvalue of $1$. Then show that the corresponding eigenspace has dimension $2$ and find the corresponding eigenvectors with sum $1$.<br><br>\n",
    "  1. Let's label the two stationary distributions $s_1$ and $s_2$. Suppose that we know that the system has a $50\\%$ chance of starting in state $1$ and a $50\\%$ chance of starting in state $3$. Write down the initial vector $v$ corresponding to this situation. Find the limit $\\displaystyle\\lim_{n\\to\\infty}A^n v$ experimentally.<br><br>\n",
    "  1. Explain why this limit must be in the eigenspace of $s_1$ and $s_2$, then express it as a linear combination of those two vectors. Why was your result predictable?<br><br>\n",
    "  1. Suppose that we know that the system has a $20\\%$ chance of starting in state $1$, a $50\\%$ chance of starting in state $2$, a $20\\%$ chance of starting in state $3$, and a $10\\%$ chance of starting in state $4$. Compute the stationary distribution, then confirm your result experimentally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5  1.   0.25 1.  ]\n",
      "[[-0.70710678 -0.24253563  0.          0.        ]\n",
      " [ 0.70710678 -0.9701425   0.          0.        ]\n",
      " [-0.          0.         -0.70710678 -0.5547002 ]\n",
      " [-0.          0.          0.70710678 -0.83205029]]\n",
      "[ 0.2  0.8 -0.  -0. ]\n",
      "[-0.  -0.   0.4  0.6]\n",
      "[0.1 0.4 0.2 0.3]\n",
      "[0.14 0.56 0.12 0.18]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[.6, .1, 0, 0],[.4, .9, 0, 0],[0, 0, .55, .3],[0, 0, .45, .7]])\n",
    "#solve det(A-lambda*I3)\n",
    "w,v = np.linalg.eig(A)\n",
    "print(w)\n",
    "print(v)\n",
    "s1 = v[:,1]/np.sum(v[:,1])\n",
    "s2 = v[:,3]/np.sum(v[:,3])\n",
    "print(s1)\n",
    "print(s2)\n",
    "\n",
    "A =np.linalg.matrix_power(A,20)\n",
    "\n",
    "#weights of eigenvectors are the probability of going to either set.\n",
    "\n",
    "print(0.5*s1+0.5*s2)\n",
    "\n",
    "print(print(0.7*s1+0.3*s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drunkard's Stumble\n",
    "\n",
    "**Question 13** Consider a drunk person stumbling sideways in a narrow alley. Suppose that they start in the middle of the alley, and if they hit either side, they fall down and stop moving. Suppose also that they can take one step in either direction without hitting the side, but that if they take two steps away from the middle in either direction, they hit the side. Lastly, suppose that regardless of where they are (except the sides), they have a $75\\%$ chance of stumbling right, and a $25\\%$ chance of stumbling left.\n",
    "\n",
    "  1. Explain why a Markov chain with five states models this situation, draw the state space diagram for it (you can use the page [here](https://graphonline.ru/en/)), and write down its transition matrix $A$.<br><br>\n",
    "  1. In the long term, what will happen? (Hint: there are two possibilties.)<br><br>\n",
    "  1. Given your last answer, what do you think are two eigenvectors (with sum 1) of your transition matrix? (Recall: eigenvectors are stationary distributions!)<br><br>\n",
    "  1. Using row reduction code (or by hand), show that your last answer is correct.<br><br>\n",
    "  1. Suppose that you know for sure that the drunkard starts in the middle of the alley. Write down the state vector $v$ for this. Experimentally find $\\displaystyle\\lim_{n\\to\\infty} A^nv$. Explain why your result makes sense.<br><br>\n",
    "  1. Suppose that your initial state vector is $v=[0,0.9,0.1,0,0]^T$. Repeat the previous question. Again, explain why your result makes sense.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   0.25 0.   0.   0.  ]\n",
      " [0.   0.   0.25 0.   0.  ]\n",
      " [0.   0.75 0.   0.25 0.  ]\n",
      " [0.   0.   0.75 0.   0.  ]\n",
      " [0.   0.   0.   0.75 1.  ]]\n",
      "[[-0.  1.  0.  0. -0.]\n",
      " [-0. -0.  1.  0. -0.]\n",
      " [-0. -0. -0.  1. -0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1, .25, 0, 0, 0],[0, 0, .25, 0, 0],[0, .75, 0, .25, 0],[0, 0, .75, 0, 0],[0, 0, 0, .75, 1]])\n",
    "print(A)\n",
    "\n",
    "AA = A - np.eye(5)\n",
    "AA = rref(AA)\n",
    "print(AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we have two *absorbing states*. That is, states that the chain cannot leave once it hits them. In such cases, we have two very simple eigenvectors with sum 1. Like in the case of a disconnected chain, the limit $\\displaystyle\\lim_{n\\to\\infty} A^nv$ depends on the initial vector. It is possible, though somewhat harder, to compute the limit given an initial vector $v$. If you're interested in the details, you can look up the 'Gambler's Ruin' problem, of which this is a special case.\n",
    "\n",
    "### Reducible Markov Chains\n",
    "\n",
    "**Definition** A Markov chain is *irreducible* if any state can be reached from any other state. Otherwise, the chain is *reducible*.\n",
    "\n",
    "**Question 14** Explain why both the above Markov chains are reducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Periodic Markov Chains\n",
    "\n",
    "**Question 15** Consider a square. You start on some corner. At every step, you have a $50\\%$ chance of moving one corner clockwise, and a $50\\%$ chance of moving one corner anticlockwise.\n",
    "  1. Label the top-left corner $A$, then the rest $B$, $C$, and $D$ in clockwise order. Draw a state space diagram corresponding to this situation (again, use [this](https://graphonline.ru/en/) link) and write down the transition matrix $A$.<br><br>\n",
    "  1. Suppose that you start in corner $A$. Which states can you be in one step later? Two steps later? Three steps later? Four steps later? Generalize.<br><br>\n",
    "  1. Suppose again that you know that at time $0$, you are in corner $A$. Write down the state vector corresponding to this, and experimentally explore the limit $\\displaystyle\\lim_{n\\to\\infty} A^nv$. Does the limit exist? What happens?<br><br>\n",
    "  1. Now suppose that instead, you have a $10\\%$ chance of starting in corner $A$, a $20\\%$ of starting in corner $B$, a $30\\%$ of starting in corner $C$, and $40\\%$ of starting in corner $D$. Repeat the above question.<br><br>\n",
    "  1. Lastly, suppose instead that you have an equal chance of starting in any given corner. Repeat the previous question.<br><br>\n",
    "  1. Without computing, what do you think is an eigenvector corresponding to eigenvalue $1$ is? Test your hypothesis.<br><br>\n",
    "  1. Examine powers of the matrix $A$ itself. What do these matrix powers tell you? How do they relate to your answer to the second question above?\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.5 0.  0.5]\n",
      " [0.5 0.  0.5 0. ]\n",
      " [0.  0.5 0.  0.5]\n",
      " [0.5 0.  0.5 0. ]]\n",
      "[0.2 0.3 0.2 0.3]\n",
      "[0.3 0.2 0.3 0.2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([[0,0.5,0,0.5],[0.5,0,0.5,0],[0,0.5,0,0.5],[0.5,0,0.5,0]])\n",
    "print(A)\n",
    "\n",
    "v0 = np.array([1,0,0,0])\n",
    "v0 = np.array([.25,.25,.25,.25])\n",
    "v0 = np.array([0.1,0.2,0.3,0.4])\n",
    "v200 = np.linalg.matrix_power(A,200)@v0\n",
    "v201 = np.linalg.matrix_power(A,201)@v0\n",
    "w,\n",
    "\n",
    "print(v200)\n",
    "print(v201)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Markov chain is an example of a *periodic* chain. In this case, we say it has period 2. We will see a Markov chain with a different period on the homework.\n",
    "\n",
    "The definition of periodicity is a bit complicated, but here goes:\n",
    "> A state in a Markov chain has period *k* if any return to it must occur in mutiples of *k* steps. For example, if we are now in a given state, and we can only return to it after 5, 10, 15, etc. steps, the state has period 5.\n",
    "> If all states have a period *k*, we say the entire chain is *k*-periodic. You can read a more formal and general definition [here](https://en.wikipedia.org/wiki/Markov_chain#Periodicity).\n",
    "\n",
    "Note that this Markov chain certainly irreducible: every state can be reached from any other state.  However, if we start in a given state, at any given time later, there are states we cannot be in. That is, there are always going to be entries of $0$ in $A^n$ for any given power $n$. This is always the case with periodic Markov chains.\n",
    "\n",
    "### Regular Matrices and Markov Chains\n",
    "\n",
    "**Definition** A column stochastic matrix is *regular* if for some number $n$, all the entries of $A^n$ are non-zero.\n",
    "\n",
    "**Question 16** We just saw that periodic Markov chains cannot have regular transition matrices. Explain why a reducible Markov chain cannot have a regular transition matrix either.\n",
    "\n",
    "In fact, we have the following:\n",
    "\n",
    "## Fundamental Theorem of Markov Chains\n",
    "If a Markov chain is irreducible and aperiodic, then:\n",
    "\n",
    "* It has a unique stationary distribution. That is, it has an eigenvalue of one with algebraic multiplicity one.<br><br> \n",
    "* Its transition matrix is regular.<br><br>\n",
    "* The limit $\\displaystyle\\lim_{n\\to\\infty}A^n v$ converges for any vector $v$ whose sum is 1. Further, this limit is the stationary distribution.\n",
    "\n",
    "Proving this is beyond the scope of our class, but I hope you see why it may be true, given your work above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
